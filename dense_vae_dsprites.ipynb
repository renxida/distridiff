{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dense_vae_dsprites'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install pillow matplotlib numpy pandas scipy sklearn imageio keras seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "# import tensorflow_probability as tfp\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "26ScWNvYSgQg"
   },
   "source": [
    "Copyright 2017 Google Inc.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "\n",
    "# dSprites - Disentanglement testing Sprites dataset\n",
    "\n",
    "## Description\n",
    "Procedurally generated 2D shapes dataset. This dataset uses 6 latents, controlling the color, shape, scale, rotation and position of a sprite (color isn't varying here, its value is fixed).\n",
    "\n",
    "All possible combinations of the latents are present.\n",
    "\n",
    "The ordering of images in the dataset (i.e. shape[0] in all ndarrays) is fixed and meaningful, see below.\n",
    "\n",
    "We chose the smallest changes in latent values that generated different pixel outputs at our 64x64 resolution after rasterization.\n",
    "\n",
    "No noise added, single image sample for a given latent setting.\n",
    "\n",
    "## Details about the ordering of the dataset\n",
    "\n",
    "The dataset was generated procedurally, and its order is deterministic.\n",
    "For example, the image at index 0 corresponds to the latents (0, 0, 0, 0, 0, 0).\n",
    "\n",
    "Then the image at index 1 increases the least significant \"bit\" of the latent:\n",
    "(0, 0, 0, 0, 0, 1)\n",
    "\n",
    "And similarly, till we reach index 32, where we get (0, 0, 0, 0, 1, 0). \n",
    "\n",
    "Hence the dataset is sequentially addressable using variable bases for every \"bit\".\n",
    "Using dataset['metadata']['latents_sizes'] makes this conversion trivial, see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jJ02BsnqSa96"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Change figure aesthetics\n",
    "%matplotlib inline\n",
    "sns.set_context('talk', font_scale=1.2, rc={'lines.linewidth': 1.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10952,
     "status": "ok",
     "timestamp": 1495021223246,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "uDL3Iw0WFw1L",
    "outputId": "1a3ce845-1add-41c3-ee3d-6018d09423bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the dataset: ['metadata', 'imgs', 'latents_classes', 'latents_values']\n",
      "Metadata: \n",
      " {b'date': b'April 2017', b'description': b'Disentanglement test Sprites dataset.Procedurally generated 2D shapes, from 6 disentangled latent factors.This dataset uses 6 latents, controlling the color, shape, scale, rotation and position of a sprite. All possible variations of the latents are present. Ordering along dimension 1 is fixed and can be mapped back to the exact latent values that generated that image.We made sure that the pixel outputs are different. No noise added.', b'version': 1, b'latents_names': (b'color', b'shape', b'scale', b'orientation', b'posX', b'posY'), b'latents_possible_values': {b'orientation': array([0.        , 0.16110732, 0.32221463, 0.48332195, 0.64442926,\n",
      "       0.80553658, 0.96664389, 1.12775121, 1.28885852, 1.44996584,\n",
      "       1.61107316, 1.77218047, 1.93328779, 2.0943951 , 2.25550242,\n",
      "       2.41660973, 2.57771705, 2.73882436, 2.89993168, 3.061039  ,\n",
      "       3.22214631, 3.38325363, 3.54436094, 3.70546826, 3.86657557,\n",
      "       4.02768289, 4.1887902 , 4.34989752, 4.51100484, 4.67211215,\n",
      "       4.83321947, 4.99432678, 5.1554341 , 5.31654141, 5.47764873,\n",
      "       5.63875604, 5.79986336, 5.96097068, 6.12207799, 6.28318531]), b'posX': array([0.        , 0.03225806, 0.06451613, 0.09677419, 0.12903226,\n",
      "       0.16129032, 0.19354839, 0.22580645, 0.25806452, 0.29032258,\n",
      "       0.32258065, 0.35483871, 0.38709677, 0.41935484, 0.4516129 ,\n",
      "       0.48387097, 0.51612903, 0.5483871 , 0.58064516, 0.61290323,\n",
      "       0.64516129, 0.67741935, 0.70967742, 0.74193548, 0.77419355,\n",
      "       0.80645161, 0.83870968, 0.87096774, 0.90322581, 0.93548387,\n",
      "       0.96774194, 1.        ]), b'posY': array([0.        , 0.03225806, 0.06451613, 0.09677419, 0.12903226,\n",
      "       0.16129032, 0.19354839, 0.22580645, 0.25806452, 0.29032258,\n",
      "       0.32258065, 0.35483871, 0.38709677, 0.41935484, 0.4516129 ,\n",
      "       0.48387097, 0.51612903, 0.5483871 , 0.58064516, 0.61290323,\n",
      "       0.64516129, 0.67741935, 0.70967742, 0.74193548, 0.77419355,\n",
      "       0.80645161, 0.83870968, 0.87096774, 0.90322581, 0.93548387,\n",
      "       0.96774194, 1.        ]), b'scale': array([0.5, 0.6, 0.7, 0.8, 0.9, 1. ]), b'shape': array([1., 2., 3.]), b'color': array([1.])}, b'latents_sizes': array([ 1,  3,  6, 40, 32, 32]), b'author': b'lmatthey@google.com', b'title': b'dSprites dataset'}\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_zip = np.load('dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz',encoding=\"bytes\")\n",
    "dataset_zip.allow_pickle=True\n",
    "print('Keys in the dataset:', list(dataset_zip.keys()))\n",
    "imgs = dataset_zip['imgs']\n",
    "latents_values = dataset_zip['latents_values']\n",
    "latents_classes = dataset_zip['latents_classes']\n",
    "metadata = dataset_zip['metadata'][()]\n",
    "\n",
    "print('Metadata: \\n', metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(737280, 64, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['imgs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9RWpIJtiHYUL"
   },
   "outputs": [],
   "source": [
    "# Define number of values per latents and functions to convert to indices\n",
    "latents_sizes = metadata[b'latents_sizes']\n",
    "latents_bases = np.concatenate((latents_sizes[::-1].cumprod()[::-1][1:],\n",
    "                                np.array([1,])))\n",
    "\n",
    "def latent_to_index(latents):\n",
    "  return np.dot(latents, latents_bases).astype(int)\n",
    "\n",
    "\n",
    "def sample_latent(size=1):\n",
    "  samples = np.zeros((size, latents_sizes.size))\n",
    "  for lat_i, lat_size in enumerate(latents_sizes):\n",
    "    samples[:, lat_i] = np.random.randint(lat_size, size=size)\n",
    "\n",
    "  return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "W8LKpGjGKaiN"
   },
   "outputs": [],
   "source": [
    "# Helper function to show images\n",
    "def show_images_grid(imgs_, num_images=25):\n",
    "  ncols = int(np.ceil(num_images**0.5))\n",
    "  nrows = int(np.ceil(num_images / ncols))\n",
    "  _, axes = plt.subplots(ncols, nrows, figsize=(nrows * 3, ncols * 3))\n",
    "  axes = axes.flatten()\n",
    "\n",
    "  for ax_i, ax in enumerate(axes):\n",
    "    if ax_i < num_images:\n",
    "      ax.imshow(imgs_[ax_i], cmap='Greys_r',  interpolation='nearest')\n",
    "      ax.set_xticks([])\n",
    "      ax.set_yticks([])\n",
    "    else:\n",
    "      ax.axis('off')\n",
    "\n",
    "def show_density(imgs):\n",
    "  _, ax = plt.subplots()\n",
    "  ax.imshow(imgs.mean(axis=0), interpolation='nearest', cmap='Greys_r')\n",
    "  ax.grid('off')\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lXSlqKKAJirL"
   },
   "source": [
    "## Randomly sampling into the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1282,
     "status": "ok",
     "timestamp": 1495021397861,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "MFJLYKK5RzbH",
    "outputId": "270d35ee-f376-47a1-9f88-1b279f70c2ca"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample latents randomly\n",
    "latents_sampled = sample_latent(size=5000)\n",
    "\n",
    "# Select images\n",
    "indices_sampled = latent_to_index(latents_sampled)\n",
    "imgs_sampled = imgs[indices_sampled]\n",
    "\n",
    "# Show images\n",
    "show_images_grid(imgs_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 125,
     "status": "ok",
     "timestamp": 1495021398201,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "IygFe_LtLoUg",
    "outputId": "8ce35c72-f502-4f8f-d0c6-71ae645662c4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the density of the data to show that no pixel ever goes out of\n",
    "# the boundary. Obviously it also means that the main support of the pixels is in the center\n",
    "# half. \n",
    "# Locations cover a square, which make the aligned X-Y latents more likely for\n",
    "# models to discover.\n",
    "\n",
    "show_density(imgs_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "peJaYLHyLKDu"
   },
   "source": [
    "## Conditional sampling of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 551,
     "status": "ok",
     "timestamp": 1495021412038,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "6DYLZkFJQjb9",
    "outputId": "601edffd-fa13-474b-e61c-0c476f00b52d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Fix posX latent to left\n",
    "latents_sampled = sample_latent(size=5000)\n",
    "latents_sampled[:, -2] = 0\n",
    "indices_sampled = latent_to_index(latents_sampled)\n",
    "imgs_sampled = imgs[indices_sampled]\n",
    "\n",
    "# Samples\n",
    "show_images_grid(imgs_sampled, 9)\n",
    "\n",
    "# Show the density too to check\n",
    "show_density(imgs_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1495021438003,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "l2g-xquoTJaG",
    "outputId": "3e3df869-eab7-4428-9749-81440506f0d6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Fix orientation to 0.8 rad\n",
    "latents_sampled = sample_latent(size=5000)\n",
    "latents_sampled[:, 3] = 5\n",
    "indices_sampled = latent_to_index(latents_sampled)\n",
    "imgs_sampled = imgs[indices_sampled]\n",
    "\n",
    "# Samples\n",
    "show_images_grid(imgs_sampled, 9)\n",
    "\n",
    "# Density should not be different than for all orientations\n",
    "show_density(imgs_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-FCACtAlqKTA"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Lambda, Conv2D, MaxPool2D, Reshape, Flatten\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import metrics\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "\n",
    "import keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 737280\n",
    "# dataset_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_all = np.arange(dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ix_train, ix_test = sklearn.model_selection.train_test_split(ix_all, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = imgs.reshape(-1, 64,64,1)\n",
    "y_raw = latents_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_raw, y_raw, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shuffle_size = 1000\n",
    "test_shuffle_size  = 1000\n",
    "batch_size = 32\n",
    "\n",
    "train_images, test_images = X_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_images(images):\n",
    "  images = images.reshape((images.shape[0], 64, 64, 1))\n",
    "  # return np.where(images > .5, 1.0, 0.0).astype('float32') / 255.0\n",
    "  return images.astype('float32')\n",
    "\n",
    "train_images = preprocess_images(train_images)\n",
    "test_images = preprocess_images(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, X, batch_size=32, shuffle=True):\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.X = X.copy()\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        X = self.X[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        return X\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataGen(train_images)\n",
    "test_dataset = CustomDataGen(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "## Define the encoder and decoder networks with *tf.keras.Sequential*\n",
    "\n",
    "In this VAE example, use two small ConvNets for the encoder and decoder networks. In the literature, these networks are also referred to as inference/recognition and generative models respectively. Use `tf.keras.Sequential` to simplify implementation. Let $x$ and $z$ denote the observation and latent variable respectively in the following descriptions.\n",
    "\n",
    "### Encoder network\n",
    "This defines the approximate posterior distribution $q(z|x)$, which takes as input an observation and outputs a set of parameters for specifying the conditional distribution of the latent representation $z$. \n",
    "In this example, simply model the distribution as a diagonal Gaussian, and the network outputs the mean and log-variance parameters of a factorized Gaussian. \n",
    "Output log-variance instead of the variance directly for numerical stability.\n",
    "\n",
    "### Decoder network \n",
    "This defines the conditional distribution of the observation $p(x|z)$, which takes a latent sample $z$ as input and outputs the parameters for a conditional distribution of the observation.\n",
    "Model the latent distribution prior $p(z)$ as a unit Gaussian.\n",
    "\n",
    "### Reparameterization trick\n",
    "To generate a sample $z$ for the decoder during training, you can sample from the latent distribution defined by the parameters outputted by the encoder, given an input observation $x$.\n",
    "However, this sampling operation creates a bottleneck because backpropagation cannot flow through a random node.\n",
    "\n",
    "To address this, use a reparameterization trick.\n",
    "In our example, you approximate $z$ using the decoder parameters and another parameter $\\epsilon$ as follows:\n",
    "\n",
    "$$z = \\mu + \\sigma \\odot \\epsilon$$\n",
    "\n",
    "where $\\mu$ and $\\sigma$ represent the mean and standard deviation of a Gaussian distribution respectively. They can be derived from the decoder output. The $\\epsilon$ can be thought of as a random noise used to maintain stochasticity of $z$. Generate $\\epsilon$ from a standard normal distribution.\n",
    "\n",
    "The latent variable $z$ is now generated by a function of $\\mu$, $\\sigma$ and $\\epsilon$, which would enable the model to backpropagate gradients in the encoder through $\\mu$ and $\\sigma$ respectively, while maintaining stochasticity through $\\epsilon$.\n",
    "\n",
    "### Network architecture\n",
    "For the encoder network, use two convolutional layers followed by a fully-connected layer. In the decoder network, mirror this architecture by using a fully-connected layer followed by three convolution transpose layers (a.k.a. deconvolutional layers in some contexts). Note, it's common practice to avoid using batch normalization when training VAEs, since the additional stochasticity due to using mini-batches may aggravate instability on top of the stochasticity from sampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "@tf.function\n",
    "def log_normal_pdf(\n",
    "    sample,\n",
    "    mean,\n",
    "    logvar,\n",
    "    raxis=1,\n",
    "    ):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(-.5 * ((sample - mean) ** 2. * tf.exp(-logvar)\n",
    "                         + logvar + log2pi), axis=raxis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VGLbvBEmjK0a",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSampling\u001b[39;00m(\u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLayer):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class VAE(tf.keras.Model):\n",
    "    \n",
    "    def create_network(self,input_shape = (64,64,1), latent_dim=6):\n",
    "        # make encoder\n",
    "        \n",
    "\n",
    "        encoder_inputs = tf.keras.Input(shape=input_shape)\n",
    "        x = encoder_inputs\n",
    "        \n",
    "\n",
    "        # x = tf.keras.layers.Conv2D(filters=32,\n",
    "        #                         kernel_size=3, strides=(2, 2),\n",
    "        #                         activation='relu')(x)\n",
    "        # x = tf.keras.layers.Conv2D(filters=64,\n",
    "        #                         kernel_size=3, strides=(2, 2),\n",
    "        #                         activation='relu')(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(32, activation='relu',)(x)\n",
    "        x = tf.keras.layers.Dense(16, activation='relu',)(x)\n",
    "        \n",
    "        z_mean = tf.keras.layers.Dense(latent_dim, activation='relu',name=\"z_mean\")(x)\n",
    "        z_log_var = tf.keras.layers.Dense(latent_dim, activation='relu',name=\"z_log_var\")(x)\n",
    "        z = Sampling()([z_mean, z_log_var])\n",
    "        encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "        \n",
    "        \n",
    "        decoder_inputs = keras.Input(shape=(latent_dim,))\n",
    "        x = decoder_inputs\n",
    "        x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dense(64*64, activation='relu')(x)\n",
    "        decoder_outputs = tf.keras.layers.Reshape(input_shape)(x)\n",
    "        decoder = keras.Model(decoder_inputs, decoder_outputs, name='decoder')\n",
    "        \n",
    "        return encoder, decoder\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        self.encoder, self.decoder = self.create_network()\n",
    "        \n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mean, logvar, z = self.encoder(x)\n",
    "        return (mean, logvar)\n",
    "\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        return Sampling()([mean, logvar])\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits\n",
    "    \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "    \n",
    "    def call(self, x):\n",
    "        mean, logvar, z = self.encoder(x)\n",
    "        return self.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## Define the loss function and the optimizer\n",
    "\n",
    "VAEs train by maximizing the evidence lower bound (ELBO) on the marginal log-likelihood:\n",
    "\n",
    "$$\\log p(x) \\ge \\text{ELBO} = \\mathbb{E}_{q(z|x)}\\left[\\log \\frac{p(x, z)}{q(z|x)}\\right].$$\n",
    "\n",
    "In practice, optimize the single sample Monte Carlo estimate of this expectation:\n",
    "\n",
    "$$\\log p(x| z) + \\log p(z) - \\log q(z|x),$$\n",
    "where $z$ is sampled from $q(z|x)$.\n",
    "\n",
    "Note: You could also analytically compute the KL term, but here you incorporate all three terms in the Monte Carlo estimator for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWCn_PVdEJZ7",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## Training\n",
    "\n",
    "* Start by iterating over the dataset\n",
    "* During each iteration, pass the image to the encoder to obtain a set of mean and log-variance parameters of the approximate posterior $q(z|x)$\n",
    "* then apply the *reparameterization trick* to sample from $q(z|x)$\n",
    "* Finally, pass the reparameterized samples to the decoder to obtain the logits of the generative distribution $p(x|z)$\n",
    "* Note: Since you use the dataset loaded by keras with 60k datapoints in the training set and 10k datapoints in the test set, our resulting ELBO on the test set is slightly higher than reported results in the literature which uses dynamic binarization of Larochelle's MNIST.\n",
    "\n",
    "### Generating images\n",
    "\n",
    "* After training, it is time to generate some images\n",
    "* Start by sampling a set of latent vectors from the unit Gaussian prior distribution $p(z)$\n",
    "* The generator will then convert the latent sample $z$ to logits of the observation, giving a distribution $p(x|z)$\n",
    "* Here, plot the probabilities of Bernoulli distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "NS2GWywBbAWo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "# set the dimensionality of the latent space to a plane for visualization later\n",
    "latent_dim = 6\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement.\n",
    "model = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Path(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(s.glob(\"image*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "class ImageSaver(Callback):\n",
    "    \n",
    "    def __init__(self, log_dir, test_sample):\n",
    "        super().__init__()\n",
    "\n",
    "        self.test_sample = test_sample\n",
    "        self.log_dir = Path(log_dir)\n",
    "        self.log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        # self.writer = tf.summary.FileWriter(self.log_dir, filename_suffix='images')\n",
    "\n",
    "    def on_train_begin(self, _):\n",
    "        self.on_epoch_end(0)\n",
    "\n",
    "    def on_train_end(self, _):\n",
    "        anim_file = self.log_dir.joinpath('epoch_progress.gif')\n",
    "\n",
    "        with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "            filenames = list(self.log_dir.glob('image*.png'))\n",
    "            filenames = sorted(filenames)\n",
    "            for filename in filenames:\n",
    "                image = imageio.imread(filename)\n",
    "                writer.append_data(image)\n",
    "        import tensorflow_docs.vis.embed as embed\n",
    "        embed.embed_file(anim_file)\n",
    "        \n",
    "                \n",
    "    def generate_and_save_images(self, epoch):\n",
    "        model = self.model\n",
    "        test_sample = self.test_sample\n",
    "        (mean, logvar) = model.encode(test_sample)\n",
    "        z = model.reparameterize(mean, logvar)\n",
    "        predictions = model.sample(z)\n",
    "        fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "        for i in range(predictions.shape[0]):\n",
    "            plt.subplot(4, 4, i + 1)\n",
    "            plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "            plt.axis('off')\n",
    "            \n",
    "        plt.savefig(self.log_dir.joinpath('image_at_epoch_{:04d}.png'.format(epoch)))\n",
    "        # plt.show()\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.generate_and_save_images(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "swCyrbqQQ-Ri",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pick a sample of the test set for generating output images\n",
    "assert batch_size >= num_examples_to_generate\n",
    "assert test_dataset.shuffle\n",
    "test_dataset.on_epoch_end() # shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17280, 5760)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset),len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=f\"{model_name}/checkpoints\", \n",
    "    save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = [test_dataset[42][i] for i in range(num_examples_to_generate)]\n",
    "test_sample = np.array(test_sample)\n",
    "\n",
    "callbacks = [\n",
    "    cp_callback,\n",
    "    ImageSaver(log_dir=f\"{model_name}/progress_images\", test_sample=test_sample)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 16:14:19.616312: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 7605\n",
      "2022-05-04 16:14:19.787361: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2022-05-04 16:14:19.875524: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13409/17280 [======================>.......] - ETA: 22s - loss: 623.1141 - reconstruction_loss: 459.5020 - kl_loss: 40.7073"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape = (None,) + (64,64,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"saved_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4M_vIbUi7c0"
   },
   "source": [
    "### Display a generated image from the last training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ZqAEtdqUmJF"
   },
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(\"vae_training_progress_images/epoch_progress.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "name": "deepmind_2d_shapes_dataset_public.ipynb",
   "provenance": [
    {
     "file_id": "/piper/depot/google3/experimental/deepmind/concepts/dataset2dshapes/public/deepmind_2d_shapes_dataset.ipynb?workspaceId=lmatthey:lmatthey-2dshapes-dataset:580:citc",
     "timestamp": 1493149332589
    },
    {
     "file_id": "0BxLiVtkN33-wbmVnbVQwcUhjY0U",
     "timestamp": 1493149291483
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
